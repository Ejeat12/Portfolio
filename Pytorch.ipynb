{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2dmQsYqPOTESOW/kJewhh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ejeat12/Profolio/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "h6lTROxU7fCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient calculations with AutoGrad"
      ],
      "metadata": {
        "id": "mMXXBeG1AIxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient calculations of x,y,z\n",
        "x = torch.randn([3], requires_grad= True)\n",
        "y = x + 2\n",
        "z = y*y*2\n",
        "# calculate dz/dx\n",
        "z.backward(x)\n",
        "print(y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ealI0d0t7vaa",
        "outputId": "0c9e3721-e8aa-4c05-8443-733334ae441a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3.0522, 1.6226, 2.6621], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevent gradient histroy\n",
        "with torch.no_grad():\n",
        "  y = x + 2\n",
        "y\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBBfUwA3AGAe",
        "outputId": "e3cc027f-2c7d-47e7-f41e-c3bccf279014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.0522, 1.6226, 2.6621])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BackPropagation"
      ],
      "metadata": {
        "id": "Q_doUaDaGkUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inputs\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# Parameters\n",
        "w = torch.tensor(1.0, requires_grad= True)\n",
        "\n",
        "# Forward pass and compute loss\n",
        "y_hat = x * w\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "w.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN5wnsXpGoD3",
        "outputId": "a065ab3d-433b-49a1-96e6-242b00c9b8c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent with Autograd and Backpropagation"
      ],
      "metadata": {
        "id": "ajPjLrQZd1e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initalize inputs and weights\n",
        "x = torch.tensor([1,2,3,4], dtype = torch.float32)\n",
        "y = torch.tensor([2,4,6,8], dtype = torch.float32)\n",
        "w = torch.tensor(0.0, requires_grad= True)\n",
        "\n",
        "# Model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# Loss\n",
        "def loss(y, y_pred):\n",
        "  return((y- y_pred)**2).mean()\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 1e-2\n",
        "epochs = 100\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  \n",
        "  # Prediction = forward pass\n",
        "  y_hat = forward(x)\n",
        "    \n",
        "    \n",
        "  #loss\n",
        "  l = loss(y, y_hat)\n",
        "    \n",
        "    \n",
        "  # calculate gradients\n",
        "  l.backward()\n",
        "    \n",
        "  \n",
        "  # update weights with gradient descent\n",
        "  with torch.no_grad():\n",
        "    \n",
        "   w-= learning_rate * w.grad\n",
        "  \n",
        "  \n",
        "  # empty weights\n",
        "  w.grad.zero_()\n",
        "  \n",
        " \n",
        "  \n",
        "  # Get info about training steps\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch: {epoch+1}, loss: {l:.8f}\")\n",
        "    print(f\"prediction after training: {forward(5):.3f}\")\n",
        " \n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptI6w5WSexCn",
        "outputId": "3d1cefe6-9680-48ee-9c3a-90afa01fa927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 30.00000000\n",
            "prediction after training: 1.500\n",
            "epoch: 11, loss: 1.16278565\n",
            "prediction after training: 8.327\n",
            "epoch: 21, loss: 0.04506890\n",
            "prediction after training: 9.671\n",
            "epoch: 31, loss: 0.00174685\n",
            "prediction after training: 9.935\n",
            "epoch: 41, loss: 0.00006770\n",
            "prediction after training: 9.987\n",
            "epoch: 51, loss: 0.00000262\n",
            "prediction after training: 9.997\n",
            "epoch: 61, loss: 0.00000010\n",
            "prediction after training: 10.000\n",
            "epoch: 71, loss: 0.00000000\n",
            "prediction after training: 10.000\n",
            "epoch: 81, loss: 0.00000000\n",
            "prediction after training: 10.000\n",
            "epoch: 91, loss: 0.00000000\n",
            "prediction after training: 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline: Model, Loss, and Optimizer"
      ],
      "metadata": {
        "id": "aFFmajYA98yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import optimizer\n",
        "from torch.nn.modules.linear import Linear\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype = torch.float32)\n",
        "y = torch.tensor([[2],[4],[6],[8]], dtype = torch.float32)\n",
        "\n",
        "\n",
        "\n",
        "# 0) create a test sample\n",
        "x_test = torch.tensor([5], dtype = torch.float32)\n",
        "\n",
        "\n",
        "# 1) Design input and ouput shape of model\n",
        "n_samples, n_features = X.shape\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# Build a custom model class\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "\n",
        "# 2) Define hyperparameters\n",
        "learning_rate = 1e-2\n",
        "epochs = 100\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  \n",
        "\n",
        "    # predict = forward pass with our model\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "    # Get inforamtion\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"epoch: {epoch+1}, loss: {l:.8f}\")\n",
        "print(f'Prediction after training: f(5) = {model(x_test).item():.3f}')     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azGv-EBVS69L",
        "outputId": "3eed899f-b224-4596-f4e9-55de36b926f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 31.08114052\n",
            "epoch: 11, loss: 0.80963933\n",
            "epoch: 21, loss: 0.02612339\n",
            "epoch: 31, loss: 0.00555058\n",
            "epoch: 41, loss: 0.00473456\n",
            "epoch: 51, loss: 0.00444625\n",
            "epoch: 61, loss: 0.00418711\n",
            "epoch: 71, loss: 0.00394340\n",
            "epoch: 81, loss: 0.00371388\n",
            "epoch: 91, loss: 0.00349770\n",
            "Prediction after training: f(5) = 10.098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "a_pIOSVQaBmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "X2jgMS_7aEWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)"
      ],
      "metadata": {
        "id": "NuZsWnxlPpJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "  \n",
        "# 2) Hyperparameters\n",
        "learning_rate = 1e-2\n",
        "epochs = 100\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    l = loss(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"epoch: {epoch+1}, loss: {l.item():.8f}\")\n",
        "\n",
        "\n",
        "# step 5: get accuracy\n",
        "with torch.no_grad():\n",
        "\n",
        "  y_pred = model(X_test)\n",
        "  y_pred_class = y_pred.round()\n",
        "  accuracy = y_pred_class.eq(y_test).sum() / float(y_test.shape[0])\n",
        "  print(f\"accuracy: {accuracy.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK0VrfiJPpcd",
        "outputId": "037741e8-c40e-4471-93f6-156a06870bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 1.17586195\n",
            "epoch: 11, loss: 0.81495833\n",
            "epoch: 21, loss: 0.60845131\n",
            "epoch: 31, loss: 0.49141195\n",
            "epoch: 41, loss: 0.41879171\n",
            "epoch: 51, loss: 0.36955634\n",
            "epoch: 61, loss: 0.33387169\n",
            "epoch: 71, loss: 0.30669358\n",
            "epoch: 81, loss: 0.28520012\n",
            "epoch: 91, loss: 0.26769727\n",
            "accuracy: 0.9211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Softmax and Cross Entropy in PyTorch"
      ],
      "metadata": {
        "id": "3-HxialmQEUp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRMlmJ9Zle7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 1:Train a model(basic)"
      ],
      "metadata": {
        "id": "eHydUW3dvwcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning -qq\n",
        "!pip install --upgrade wandb -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQRkyD4X7QqV",
        "outputId": "1ace08fb-dd8d-4322-85b3-3db18aaa279e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.8/198.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import pytorch_lightning as pl\n"
      ],
      "metadata": {
        "id": "uK_OUF4DxdnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l1(x)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.l1(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "kv0MbuTOD7VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LitAutoEncoder(pl.LightningModule):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defines the train loop.\n",
        "        x, y = batch\n",
        "        x = x.view(x.size(0), -1)\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n"
      ],
      "metadata": {
        "id": "rNvVDVgzF11a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the training set\n",
        "dataset = MNIST(os.getcwd(), download = True, transform = transforms.ToTensor())\n",
        "train_loader = DataLoader(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJsvuCes42CN",
        "outputId": "e8ffa929-a568-4acf-9c65-e57538a9d352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 430176633.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-images-idx3-ubyte.gz to /content/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 38590536.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 165479659.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6519688.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  define model\n",
        "autoencoder = LitAutoEncoder(Encoder(), Decoder())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WHdvdDrh5cma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train without training loop\n",
        "optimizer = autoencoder.configure_optimizers()\n",
        "\n",
        "for batch_idx, batch in enumerate(train_loader):\n",
        "  loss = autoencoder.training_step(batch, batch_idx)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n"
      ],
      "metadata": {
        "id": "ECH2V3iN7-Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level 2:ADD A VALIDATION AND TEST SET"
      ],
      "metadata": {
        "id": "2ckeAbCF9WAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "uxdKxSpm9cn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "transform = transforms.ToTensor()\n",
        "train_data = datasets.MNIST(root = \"MNIST\", download = True, train = True, transform = transform)\n",
        "test_data = datasets.MNIST(root = \"MNIST\", download = True, train = True, transform = transform)"
      ],
      "metadata": {
        "id": "LnOKb4GE-j95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d94c03-dc7d-43dd-8808-4be95f40214c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 99608786.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/train-images-idx3-ubyte.gz to MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 94049451.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 24102053.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22438785.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a test loop\n",
        "class LitAutoEncoder(pl.LightningModule):\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    pass\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    x = x.view(x.size(0), -1)\n",
        "    z = self.encoder(x)\n",
        "    x_hat = self.decoder(z)\n",
        "    test_loss = F.mse_loss(x_hat, x)\n",
        "    self.log(\"test loss\", test_loss)\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "X5okojxhZtCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the test loop\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import Trainer\n",
        "\n",
        "# initlaizae the trainer\n",
        "trainer = Trainer()\n",
        "trainer.test(model, dataloaders = DataLoader(test_data))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_mPfGw6IbFBO",
        "outputId": "daea7299-21f0-4452-8af3-f5078f141dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8d3a592785a6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# initlaizae the trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_model_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`Trainer` requires either a `model` or `model_init` argument\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: `Trainer` requires either a `model` or `model_init` argument"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train both data and validation split\n",
        "trainer = Trainer()\n",
        "train_loader = DataLoader(train_data)\n",
        "val_loader = DataLoader(val_data)\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "metadata": {
        "id": "EdCwoiJXc7TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a checkpoint to a specfic path at every epoch end\n",
        "trainer = Trainer(default_root_dir = \"some/path/\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d_1eLNRVeH8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a lightning module based on checkpoint\n",
        "model = LitAutoEncoder.load_from_checkpoint(\"some/path/\")\n",
        "#disable dropout\n",
        "model.eval()\n",
        "# make prediction with x\n",
        "y_pred = model(x)"
      ],
      "metadata": {
        "id": "GOLSuuJJfIKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save hyperparameters\n",
        "class LitAutoEncoder(pl.lightningModule):\n",
        "  def _init_(self, learning_rate):\n",
        "    super()._init_()\n",
        "    self.save_hyperparameters()"
      ],
      "metadata": {
        "id": "qJ4mdmRff_Go"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}